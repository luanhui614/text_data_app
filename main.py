import streamlit as st
import pandas as pd
import plotly.express as px
import requests
import json
from typing import Union
from openai import OpenAI
import os
import tempfile


class DataAnalyzer:
    def __init__(self, api_key: str, api_type: str):
        self.api_key = api_key
        self.api_type = api_type
        self.df = None

    def load_data(self, file: Union[str, bytes]) -> bool:
        """åŠ è½½æ•°æ®æ–‡ä»¶"""
        try:
            if file.name.endswith('.xlsx'):
                self.df = pd.read_excel(file)
            elif file.name.endswith('.csv'):
                self.df = pd.read_csv(file)
            return True
        except Exception as e:
            st.error(f"æ–‡ä»¶åŠ è½½é”™è¯¯: {str(e)}")
            return False

    def process_query(self, query: str) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        if self.df is None:
            return "è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶"

        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æåŠ©æ‰‹ã€‚å½“å‰æ•°æ®é›†åŒ…å«ä»¥ä¸‹åˆ—ï¼š
{', '.join(self.df.columns)}
æ•°æ®å½¢çŠ¶ï¼š{self.df.shape}

ä½ çš„ä»»åŠ¡æ˜¯ï¼š
1. ç†è§£ç”¨æˆ·çš„æ•°æ®åˆ†æéœ€æ±‚
2. ç”Ÿæˆç›¸åº”çš„Pythonä»£ç 
3. è¿”å›æ ¼å¼åŒ–çš„Markdownä»£ç å—ï¼Œå…¶ä¸­åŒ…å«å¯æ‰§è¡Œçš„Pythonä»£ç 

æ³¨æ„ï¼š
- ä½¿ç”¨ 'df' ä½œä¸ºæ•°æ®æ¡†çš„å˜é‡å
- å¯¹äºå¯è§†åŒ–ï¼Œä½¿ç”¨ plotly.express
- ä»£ç åº”è¯¥å¯ä»¥ç›´æ¥åœ¨Streamlitç¯å¢ƒä¸­è¿è¡Œ
- å¦‚æœéœ€è¦æ˜¾ç¤ºå›¾è¡¨ï¼Œä½¿ç”¨ st.plotly_chart()
"""

        try:
            if self.api_type == "DeepSeek":
                return self._call_deepseek(system_prompt, query)
            elif self.api_type == "Qwen":
                return self._call_qwen(system_prompt, query)
            elif self.api_type == "Kimi":
                return self._call_kimi(system_prompt, query)
            elif self.api_type == "è±†åŒ…":
                return self._call_doubao(system_prompt, query)
            elif self.api_type == "æ™ºè°±":
                return self._call_zhipu(system_prompt, query)
            else:
                return "ä¸æ”¯æŒçš„APIç±»å‹"
        except Exception as e:
            return f"APIè°ƒç”¨å¤±è´¥: {str(e)}"

    def _call_deepseek(self, system_prompt, query):
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        data = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ],
            "temperature": 0.1
        }
        response = requests.post(
            "https://api.deepseek.com/v1/chat/completions",
            headers=headers,
            json=data
        )
        return response.json()["choices"][0]["message"]["content"]

    #
    # def _call_qwen(self, system_prompt, query):
    #     headers = {
    #         "Content-Type": "application/json",
    #         "Authorization": f"Bearer {self.api_key}"
    #     }
    #     data = {
    #         "model": "qwen-max",
    #         "messages": [
    #             {"role": "system", "content": system_prompt},
    #             {"role": "user", "content": query}
    #         ],
    #         "temperature": 0.1
    #     }
    #     response = requests.post(
    #         "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation",
    #         headers=headers,
    #         json=data
    #     )
    #     return response.json()["output"]["choices"][0]["message"]["content"]

    def _call_qwen(self, system_prompt, query):
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        data = {
            "model": "deepseek-r1-distill-qwen-7b",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ],
            "temperature": 0.1
        }
        response = requests.post(
            "https://dashscope.aliyuncs.com/compatible-mode/v1",
            headers=headers,
            json=data
        )
        return response.json()["choices"][0]["message"]["content"]

    def _call_kimi(self, system_prompt, query):
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        data = {
            "model": "moonshot-v1-8k",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ],
            "temperature": 0.1
        }
        response = requests.post(
            "https://api.moonshot.cn/v1/chat/completions",
            headers=headers,
            json=data
        )
        return response.json()["choices"][0]["message"]["content"]

    def _call_doubao(self, system_prompt, query):
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        data = {
            "model": "skylark2-pro-4k",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ],
            "temperature": 0.1
        }
        response = requests.post(
            "https://open.byteflowapi.com/api/v1/chat/completions",
            headers=headers,
            json=data
        )
        return response.json()["choices"][0]["message"]["content"]

    def _call_zhipu(self, system_prompt, query):
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        data = {
            "model": "chatglm-pro",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": query}
            ],
            "temperature": 0.1
        }
        response = requests.post(
            "https://open.bigmodel.cn/api/paas/v3/chat/completions",
            headers=headers,
            json=data
        )
        return response.json()["choices"][0]["message"]["content"]


def main():
    st.title("ğŸ“Š æ™ºèƒ½æ•°æ®åˆ†æåŠ©æ‰‹")

    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")

        # APIç±»å‹é€‰æ‹©
        api_type = st.selectbox(
            "é€‰æ‹©AIæ¨¡å‹",
            ["DeepSeek", "Qwen", "Kimi", "è±†åŒ…", "æ™ºè°±"],
            index=0,
            help="é€‰æ‹©éœ€è¦ä½¿ç”¨çš„AIæ¨¡å‹"
        )

        # æ ¹æ®é€‰æ‹©çš„APIç±»å‹æ˜¾ç¤ºå¯¹åº”çš„è¾“å…¥æ¡†
        api_key = st.text_input(
            f"è¾“å…¥{api_type} API Key",
            type="password",
            help=f"è¾“å…¥{api_type}çš„API Keyä»¥å¯ç”¨AIåˆ†æåŠŸèƒ½"
        )

        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æ•°æ®æ–‡ä»¶",
            type=['csv', 'xlsx'],
            help="æ”¯æŒCSVå’ŒExcelæ–‡ä»¶"
        )

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'analyzer' not in st.session_state:
        st.session_state.analyzer = None

    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []

    # è®¾ç½®API keyå’ŒåŠ è½½æ•°æ®
    if api_key and uploaded_file:
        if st.session_state.analyzer is None or \
                st.session_state.analyzer.api_type != api_type or \
                st.session_state.analyzer.api_key != api_key:
            st.session_state.analyzer = DataAnalyzer(api_key, api_type)

        if st.session_state.analyzer.df is None:
            if st.session_state.analyzer.load_data(uploaded_file):
                st.success("æ•°æ®åŠ è½½æˆåŠŸï¼")
                # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
                st.subheader("æ•°æ®é¢„è§ˆ")
                st.dataframe(st.session_state.analyzer.df.head())

    # èŠå¤©ç•Œé¢
    st.subheader("ğŸ’¬ ä¸AIå¯¹è¯")

    # ç”¨æˆ·è¾“å…¥
    user_input = st.chat_input("è¾“å…¥ä½ çš„æ•°æ®åˆ†æéœ€æ±‚...")

    if user_input:
        if st.session_state.analyzer is None:
            st.error("è¯·å…ˆé…ç½®API Keyå’Œä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼")
            return

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        st.session_state.chat_history.append({"role": "user", "content": user_input})

        # è·å–AIå“åº”
        with st.spinner("AIæ­£åœ¨æ€è€ƒ..."):
            response = st.session_state.analyzer.process_query(user_input)
            st.session_state.chat_history.append({"role": "assistant", "content": response})

    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

            # å¦‚æœæ¶ˆæ¯ä¸­åŒ…å«ä»£ç å—ï¼Œåˆ™å°è¯•æ‰§è¡Œ
            if message["role"] == "assistant" and "```python" in message["content"]:
                code = message["content"].split("```python")[1].split("```")[0]
                try:
                    with st.expander("æŸ¥çœ‹æ‰§è¡Œç»“æœ"):
                        exec(code)
                except Exception as e:
                    st.error(f"ä»£ç æ‰§è¡Œé”™è¯¯: {str(e)}")


if __name__ == "__main__":
    main()